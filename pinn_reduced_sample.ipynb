{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418734e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import argparse\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e15c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950ed094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Reynolds Number: 10\n",
      "\n",
      "Output Reynolds Number: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Re = 10\n",
    "Re_in = 100\n",
    "nu = 1/Re\n",
    "\n",
    "f1 = open('Re_{}.txt'.format(Re), 'a+')\n",
    "print('Input Reynolds Number: {}\\n'.format(Re))\n",
    "print('Output Reynolds Number: {}\\n'.format(Re_in))\n",
    "\n",
    "f = h5py.File('data/boundary_points.h5', 'r')\n",
    "X_bc = f['X_bc']\n",
    "Y_bc = f['Y_bc']\n",
    "X_bc = np.asarray(X_bc)\n",
    "Y_bc = np.asarray(Y_bc)\n",
    "f.close()\n",
    "\n",
    "f = h5py.File('data/Analytical_Solutions/boundary/Re_{}.h5'.format(Re), 'r')\n",
    "S_bc = f['S_bc']\n",
    "S_bc = np.asarray(S_bc)\n",
    "f.close()\n",
    "\n",
    "X_bc = Variable(torch.from_numpy(X_bc).float(), requires_grad=False).to(device)\n",
    "Y_bc = Variable(torch.from_numpy(Y_bc).float(), requires_grad=False).to(device)\n",
    "S_bc = Variable(torch.from_numpy(S_bc).float(), requires_grad=False).to(device)\n",
    "\n",
    "\n",
    "f = h5py.File('data/colocation_points.h5', 'r')\n",
    "X_col = f['X_col']\n",
    "Y_col = f['Y_col']\n",
    "X_col = np.asarray(X_col)\n",
    "Y_col = np.asarray(Y_col)\n",
    "f.close()\n",
    "\n",
    "f = h5py.File('data/Analytical_Solutions/colocation/Re_{}.h5'.format(Re), 'r')\n",
    "S_col = f['S_col']\n",
    "S_col = np.asarray(S_col)\n",
    "f.close()\n",
    "\n",
    "X_col = Variable(torch.from_numpy(X_col).float(), requires_grad=True).to(device)\n",
    "Y_col = Variable(torch.from_numpy(Y_col).float(), requires_grad=True).to(device)\n",
    "S_col = Variable(torch.from_numpy(S_col).float(), requires_grad=True).to(device)\n",
    "S = torch.zeros_like(X_col).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843784da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom linear layer which will take the trained weights and learn two parameters Aand B\n",
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, size_in, size_out, W, B):\n",
    "        super().__init__()\n",
    "        self.size_in = size_in\n",
    "        self.size_out = size_out\n",
    "        row_vector = torch.Tensor(size_out, 1)\n",
    "        col_vector = torch.Tensor(1, size_in)\n",
    "        self.row_vector = nn.Parameter(row_vector)\n",
    "        self.col_vector = nn.Parameter(col_vector)\n",
    "        #W =  Variable(torch.from_numpy(W).float(), requires_grad=False).to(device)\n",
    "        #B =  Variable(torch.from_numpy(B).float(), requires_grad=True).to(device)\n",
    "        self.bias = nn.Parameter(B)\n",
    "        self.W = W\n",
    "\n",
    "        nn.init.xavier_uniform_(self.row_vector)\n",
    "        nn.init.xavier_uniform_(self.col_vector)\n",
    "\n",
    "    def forward(self, x):\n",
    "        RV = torch.mm(self.row_vector, self.col_vector)\n",
    "        W_ = torch.add(self.W, RV)\n",
    "        WX = torch.mm(x, W_.T)\n",
    "        return torch.add(WX, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3cdf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(PINN, self).__init__()\n",
    "        self.weights = weights\n",
    "        W1, B1 = self.weights[0, :40].view(20, 2), weights[0, 40:60].view(20)\n",
    "        self.layer1 = CustomLinear(2, 20, W1, B1)\n",
    "        W2, B2 = self.weights[0, 60:460].view(20, 20), weights[0, 460:480].view(20)\n",
    "        self.layer2 = CustomLinear(20, 20, W2, B2)\n",
    "        W3, B3 = self.weights[0, 480:880].view(20, 20), weights[0, 880:900].view(20)\n",
    "        self.layer3 = CustomLinear(20, 20, W3, B3)\n",
    "        W4, B4 = self.weights[0, 900:1300].view(20, 20), weights[0, 1300:1320].view(20)\n",
    "        self.layer4 = CustomLinear(20, 20, W4, B4)\n",
    "        W5, B5 = self.weights[0, 1320:1720].view(20, 20), weights[0, 1720:1740].view(20)\n",
    "        self.layer5 = CustomLinear(20, 20, W5, B5)\n",
    "        W6, B6 = self.weights[0, 1740:2140].view(20, 20), weights[0, 2140:2160].view(20)\n",
    "        self.layer6 = CustomLinear(20, 20, W6, B6)\n",
    "        W7, B7 = self.weights[0, 2160:2220].view(3, 20), weights[0, 2220:2223].view(3)\n",
    "        self.output_layer = CustomLinear(20, 3, W7, B7)\n",
    "\n",
    "    def forward(self, x, y): \n",
    "        inputs = torch.cat([x, y], axis=1)\n",
    "        layer1_out = torch.tanh(self.layer1(inputs))\n",
    "        layer2_out = torch.tanh(self.layer2(layer1_out))\n",
    "        layer3_out = torch.tanh(self.layer3(layer2_out))\n",
    "        layer4_out = torch.tanh(self.layer4(layer3_out))\n",
    "        layer5_out = torch.tanh(self.layer5(layer4_out))\n",
    "        layer6_out = torch.tanh(self.layer6(layer5_out))\n",
    "        output = self.output_layer(layer6_out) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db6730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights = np.loadtxt('pinns/pretrained/weights/weights_'+str(Re_in)+'.txt')\n",
    "trained_weights = trained_weights.reshape((1,2223))\n",
    "trained_weights = Variable(torch.from_numpy(trained_weights).float(), requires_grad=False).to(device)\n",
    "pinn = PINN(trained_weights)\n",
    "pinn = pinn.to(device)\n",
    "mse_cost_function = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(pinn.parameters(), lr=1e-2)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=8000, gamma=0.1, last_epoch=-1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e047a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(x, y, pinn):\n",
    "    s = pinn.forward(x, y)\n",
    "    u = s[:,0:1]\n",
    "    v = s[:,1:2]\n",
    "    p = s[:,2:]\n",
    "\n",
    "    du_dx = torch.autograd.grad(u.sum(), x, create_graph=True)[0]\n",
    "    dv_dx = torch.autograd.grad(v.sum(), x, create_graph=True)[0]\n",
    "    dp_dx = torch.autograd.grad(p.sum(), x, create_graph=True)[0]\n",
    "\n",
    "    du_dy = torch.autograd.grad(u.sum(), y, create_graph=True)[0]\n",
    "    dv_dy = torch.autograd.grad(v.sum(), y, create_graph=True)[0]\n",
    "    dp_dy = torch.autograd.grad(p.sum(), y, create_graph=True)[0]\n",
    "\n",
    "    du_dxx = torch.autograd.grad(du_dx.sum(), x, create_graph=True)[0]\n",
    "    dv_dxx = torch.autograd.grad(dv_dx.sum(), x, create_graph=True)[0]\n",
    "    du_dyy = torch.autograd.grad(du_dy.sum(), y, create_graph=True)[0]\n",
    "    dv_dyy = torch.autograd.grad(dv_dy.sum(), y, create_graph=True)[0]\n",
    "\n",
    "    f1 = u*du_dx + v*du_dy + dp_dx - nu*(du_dxx + du_dyy)\n",
    "    f2 = u*dv_dx + v*dv_dy + dp_dy - nu*(dv_dxx + dv_dyy)\n",
    "    f3 = du_dx + dv_dy\n",
    "    f = f1 + f2 + f3\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a267888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, LR: 1.0000e-02, Loss: 8.0431e+01, Data Loss: 1.0870e+01, Physics Loss: 6.9561e+01\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "for epoch in range(iterations):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    PINN_S_bc = pinn.forward(X_bc, Y_bc)\n",
    "    MSE_U = mse_cost_function(PINN_S_bc, S_bc)\n",
    "\n",
    "    PINN_Residual = residual(X_col, Y_col, pinn)\n",
    "    MSE_F = mse_cost_function(PINN_Residual, S)\n",
    "\n",
    "    Loss = MSE_U + MSE_F\n",
    "\n",
    "    Loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "        if epoch%1000 == 0:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            f1.write('Epoch %d, LR: %.4e, Loss: %.4e, Data Loss: %.4e, Physics Loss: %.4e\\n' % (epoch, current_lr, Loss, MSE_U, MSE_F))\n",
    "            print('Epoch %d, LR: %.4e, Loss: %.4e, Data Loss: %.4e, Physics Loss: %.4e' % (epoch, current_lr, Loss, MSE_U, MSE_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfe7fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean L2 Error: 5.8354e+01\n",
      "Relative L2 Error: 5.1567e-01\n"
     ]
    }
   ],
   "source": [
    "S_pinn = pinn(X_col, Y_col)\n",
    "# Mean L2 Error\n",
    "error = torch.linalg.norm(S_col-S_pinn,2)\n",
    "print('Mean L2 Error: %.4e' % (error))\n",
    "# Relative L2 Error\n",
    "L2_error = torch.linalg.norm(S_col-S_pinn,2)/torch.linalg.norm(S_col,2)\n",
    "print('Relative L2 Error: %.4e' % (L2_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96faa575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:  layer1.row_vector torch.Size([20, 1])\n",
      "key:  layer1.col_vector torch.Size([1, 2])\n",
      "key:  layer1.bias torch.Size([20])\n",
      "key:  layer2.row_vector torch.Size([20, 1])\n",
      "key:  layer2.col_vector torch.Size([1, 20])\n",
      "key:  layer2.bias torch.Size([20])\n",
      "key:  layer3.row_vector torch.Size([20, 1])\n",
      "key:  layer3.col_vector torch.Size([1, 20])\n",
      "key:  layer3.bias torch.Size([20])\n",
      "key:  layer4.row_vector torch.Size([20, 1])\n",
      "key:  layer4.col_vector torch.Size([1, 20])\n",
      "key:  layer4.bias torch.Size([20])\n",
      "key:  layer5.row_vector torch.Size([20, 1])\n",
      "key:  layer5.col_vector torch.Size([1, 20])\n",
      "key:  layer5.bias torch.Size([20])\n",
      "key:  layer6.row_vector torch.Size([20, 1])\n",
      "key:  layer6.col_vector torch.Size([1, 20])\n",
      "key:  layer6.bias torch.Size([20])\n",
      "key:  output_layer.row_vector torch.Size([3, 1])\n",
      "key:  output_layer.col_vector torch.Size([1, 20])\n",
      "key:  output_layer.bias torch.Size([3])\n",
      "weights:  (368,)\n",
      "layer1.row_vector torch.Size([20, 1])\n",
      "layer1.col_vector torch.Size([1, 2])\n",
      "layer1.bias torch.Size([20])\n",
      "layer2.row_vector torch.Size([20, 1])\n",
      "layer2.col_vector torch.Size([1, 20])\n",
      "layer2.bias torch.Size([20])\n",
      "layer3.row_vector torch.Size([20, 1])\n",
      "layer3.col_vector torch.Size([1, 20])\n",
      "layer3.bias torch.Size([20])\n",
      "layer4.row_vector torch.Size([20, 1])\n",
      "layer4.col_vector torch.Size([1, 20])\n",
      "layer4.bias torch.Size([20])\n",
      "layer5.row_vector torch.Size([20, 1])\n",
      "layer5.col_vector torch.Size([1, 20])\n",
      "layer5.bias torch.Size([20])\n",
      "layer6.row_vector torch.Size([20, 1])\n",
      "layer6.col_vector torch.Size([1, 20])\n",
      "layer6.bias torch.Size([20])\n",
      "output_layer.row_vector torch.Size([3, 1])\n",
      "output_layer.col_vector torch.Size([1, 20])\n",
      "output_layer.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Save weights to file\n",
    "params = pinn.state_dict()\n",
    "\n",
    "flattened_weights = []\n",
    "for key in params.keys():\n",
    "    print(\"key: \", key, params[key].shape)\n",
    "    flattened_tensor = torch.reshape(params[key], (-1,)).tolist()\n",
    "    for val in flattened_tensor:\n",
    "        flattened_weights.append(val)\n",
    "weights_array = np.array(flattened_weights)\n",
    "print(\"weights: \", weights_array.shape)\n",
    "\n",
    "np.savetxt('weights_'+str(Re)+'.txt', weights_array)\n",
    "torch.save(pinn.state_dict(), 'model_'+str(Re)+'.pt')\n",
    "pinn2 = PINN(trained_weights)\n",
    "pinn2.load_state_dict(torch.load('model_'+str(Re)+'.pt'))\n",
    "\n",
    "for name, param in pinn2.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
