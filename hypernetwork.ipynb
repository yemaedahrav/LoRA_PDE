{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62cb1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca5ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reynolds numbers from 10 to 90 are used for training \n",
    "# The model is evaluated on the last 10 reynolds numbers from 91 to 100\n",
    "\n",
    "outputs = np.zeros((81, 1803))\n",
    "for Re in range(10,91,1):\n",
    "    outputs[Re-10] = np.loadtxt('pinns/weights/weights_'+str(Re)+'.txt')\n",
    "    \n",
    "inputs = np.arange(10,91,1)\n",
    "inputs = np.reshape(inputs, (inputs.shape[0],1))\n",
    "inputs = Variable(torch.from_numpy(inputs).float(), requires_grad=False).to(device)\n",
    "outputs = Variable(torch.from_numpy(outputs).float(), requires_grad=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96dd2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HyperNetwork, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(nn.Linear(1,512),\n",
    "                      nn.ReLU(),             \n",
    "                      nn.Linear(512,256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256,256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128,1803))    \n",
    "        \n",
    "    def forward(self, Re):        \n",
    "        weights = self.layers(Re)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7f6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "hnet = HyperNetwork()\n",
    "hnet = hnet.to(device)\n",
    "mse_cost_function = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(hnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4585068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss: 6.3884e-01\n",
      "Iter 100, Loss: 7.0518e-02\n",
      "Iter 200, Loss: 6.9959e-02\n",
      "Iter 300, Loss: 6.9598e-02\n",
      "Iter 400, Loss: 6.9394e-02\n",
      "Iter 500, Loss: 6.9291e-02\n",
      "Iter 600, Loss: 6.9248e-02\n",
      "Iter 700, Loss: 6.9224e-02\n",
      "Iter 800, Loss: 6.9208e-02\n",
      "Iter 900, Loss: 6.9193e-02\n",
      "Iter 1000, Loss: 6.9181e-02\n",
      "Iter 1100, Loss: 6.9170e-02\n",
      "Iter 1200, Loss: 6.9308e-02\n",
      "Iter 1300, Loss: 6.9151e-02\n",
      "Iter 1400, Loss: 6.9141e-02\n",
      "Iter 1500, Loss: 6.9129e-02\n",
      "Iter 1600, Loss: 6.9169e-02\n",
      "Iter 1700, Loss: 6.9172e-02\n",
      "Iter 1800, Loss: 6.9141e-02\n",
      "Iter 1900, Loss: 6.9138e-02\n",
      "Iter 2000, Loss: 6.9127e-02\n",
      "Iter 2100, Loss: 6.9206e-02\n",
      "Iter 2200, Loss: 6.9121e-02\n",
      "Iter 2300, Loss: 6.9111e-02\n",
      "Iter 2400, Loss: 6.9156e-02\n",
      "Iter 2500, Loss: 6.9108e-02\n",
      "Iter 2600, Loss: 6.9101e-02\n",
      "Iter 2700, Loss: 6.9108e-02\n",
      "Iter 2800, Loss: 6.9087e-02\n",
      "Iter 2900, Loss: 7.3407e-02\n",
      "Iter 3000, Loss: 7.0259e-02\n",
      "Iter 3100, Loss: 7.0220e-02\n",
      "Iter 3200, Loss: 7.0211e-02\n",
      "Iter 3300, Loss: 7.0209e-02\n",
      "Iter 3400, Loss: 7.0209e-02\n",
      "Iter 3500, Loss: 7.0209e-02\n",
      "Iter 3600, Loss: 7.0209e-02\n",
      "Iter 3700, Loss: 7.0209e-02\n",
      "Iter 3800, Loss: 7.0209e-02\n",
      "Iter 3900, Loss: 7.0209e-02\n",
      "Iter 4000, Loss: 7.0209e-02\n",
      "Iter 4100, Loss: 7.0209e-02\n",
      "Iter 4200, Loss: 7.0209e-02\n",
      "Iter 4300, Loss: 7.0209e-02\n",
      "Iter 4400, Loss: 7.0209e-02\n",
      "Iter 4500, Loss: 7.0209e-02\n",
      "Iter 4600, Loss: 7.0209e-02\n",
      "Iter 4700, Loss: 7.0209e-02\n",
      "Iter 4800, Loss: 7.0209e-02\n",
      "Iter 4900, Loss: 7.0209e-02\n",
      "Iter 5000, Loss: 7.0209e-02\n",
      "Iter 5100, Loss: 7.0209e-02\n",
      "Iter 5200, Loss: 7.0209e-02\n",
      "Iter 5300, Loss: 7.0209e-02\n",
      "Iter 5400, Loss: 7.0209e-02\n",
      "Iter 5500, Loss: 7.0209e-02\n",
      "Iter 5600, Loss: 7.0209e-02\n",
      "Iter 5700, Loss: 7.0209e-02\n",
      "Iter 5800, Loss: 7.0209e-02\n",
      "Iter 5900, Loss: 7.0209e-02\n",
      "Iter 6000, Loss: 7.0209e-02\n",
      "Iter 6100, Loss: 7.0209e-02\n",
      "Iter 6200, Loss: 7.0209e-02\n",
      "Iter 6300, Loss: 7.0209e-02\n",
      "Iter 6400, Loss: 7.0209e-02\n",
      "Iter 6500, Loss: 7.0209e-02\n",
      "Iter 6600, Loss: 7.0209e-02\n",
      "Iter 6700, Loss: 7.0209e-02\n",
      "Iter 6800, Loss: 7.0209e-02\n",
      "Iter 6900, Loss: 7.0209e-02\n",
      "Iter 7000, Loss: 7.0209e-02\n",
      "Iter 7100, Loss: 7.0209e-02\n",
      "Iter 7200, Loss: 7.0209e-02\n",
      "Iter 7300, Loss: 7.0209e-02\n",
      "Iter 7400, Loss: 7.0209e-02\n",
      "Iter 7500, Loss: 7.0209e-02\n",
      "Iter 7600, Loss: 7.0209e-02\n",
      "Iter 7700, Loss: 7.0209e-02\n",
      "Iter 7800, Loss: 7.0209e-02\n",
      "Iter 7900, Loss: 7.0209e-02\n",
      "Iter 8000, Loss: 7.0209e-02\n",
      "Iter 8100, Loss: 7.0209e-02\n",
      "Iter 8200, Loss: 7.0209e-02\n",
      "Iter 8300, Loss: 7.0209e-02\n",
      "Iter 8400, Loss: 7.0209e-02\n",
      "Iter 8500, Loss: 7.0209e-02\n",
      "Iter 8600, Loss: 7.0209e-02\n",
      "Iter 8700, Loss: 7.0209e-02\n",
      "Iter 8800, Loss: 7.0209e-02\n",
      "Iter 8900, Loss: 7.0209e-02\n",
      "Iter 9000, Loss: 7.0209e-02\n",
      "Iter 9100, Loss: 7.0209e-02\n",
      "Iter 9200, Loss: 7.0209e-02\n",
      "Iter 9300, Loss: 7.0209e-02\n",
      "Iter 9400, Loss: 7.0209e-02\n",
      "Iter 9500, Loss: 7.0209e-02\n",
      "Iter 9600, Loss: 7.0209e-02\n",
      "Iter 9700, Loss: 7.0209e-02\n",
      "Iter 9800, Loss: 7.0209e-02\n",
      "Iter 9900, Loss: 7.0209e-02\n"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "for epoch in range(iterations):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    hnet_out = hnet.forward(inputs)\n",
    "    Loss = mse_cost_function(hnet_out, outputs)\n",
    "    Loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "        if epoch%100 == 0:\n",
    "            print('Iter %d, Loss: %.4e' % (epoch, Loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "049ff99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative L2 Error: 9.996828e-01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = np.zeros((10, 1803))\n",
    "for Re in range(91,101,1):\n",
    "    outputs[Re-91] = np.loadtxt('pinns/weights/weights_'+str(Re)+'.txt')\n",
    "    \n",
    "inputs = np.arange(91,101,1)\n",
    "inputs = np.reshape(inputs, (inputs.shape[0],1))\n",
    "inputs = Variable(torch.from_numpy(inputs).float(), requires_grad=False).to(device)\n",
    "outputs = Variable(torch.from_numpy(outputs).float(), requires_grad=False).to(device)\n",
    "pred_outputs = hnet.forward(inputs)\n",
    "L2_error = torch.linalg.norm(outputs-pred_outputs,2)/torch.linalg.norm(outputs,2)\n",
    "print('Relative L2 Error: %e \\n' % (L2_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
